{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "from os import makedirs, listdir\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "import io"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot lion photos\n",
    "folder = './images/lion/'\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10)) \n",
    "for i in range(9):\n",
    "\tfilename = os.path.join(folder, os.listdir(folder)[i])\n",
    "\tax[i//3, i%3].imshow(imread(filename))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imread(os.path.join('./images/kangaroo/', os.listdir('./images/kangaroo/')[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kangaroo photos\n",
    "folder = './images/kangaroo/'\n",
    "\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i in range(9):\n",
    "\tfilename = os.path.join(folder, os.listdir(folder)[i])\n",
    "\tax[i//3, i%3].imshow(imread(filename))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Into train and test (80-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('dataset/', ignore_errors=True)\n",
    "dataset_home = 'dataset/'\n",
    "subdirs = ['train/', 'test/']\n",
    "for subdir in subdirs:\n",
    "\t# create label subdirectories\n",
    "\tlabeldirs = ['kangaroo/', 'lion/']\n",
    "\tfor labldir in labeldirs:\n",
    "\t\tnewdir = dataset_home + subdir + labldir\n",
    "\t\tmakedirs(newdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "val_ratio = 20\n",
    "testlist = np.random.choice(range(100), val_ratio, replace=False)\n",
    "\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'images/kangaroo/'\n",
    "files = listdir(src_directory)\n",
    "for i in range(100):\n",
    "\tfile = files[i]\n",
    "\tsrc = src_directory + '/' + file\n",
    "\tdst = ('dataset/test/kangaroo/' + file) if i in testlist else ('dataset/train/kangaroo/' + file)\n",
    "\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)\n",
    "val_ratio = 20\n",
    "testlist = np.random.choice(range(100), val_ratio, replace=False)\n",
    "\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'images/lion/'\n",
    "files = listdir(src_directory)\n",
    "for i in range(100):\n",
    "\tfile = files[i]\n",
    "\tsrc = src_directory + '/' + file\n",
    "\tdst = ('dataset/test/lion/' + file) if i in testlist else ('dataset/train/lion/' + file)\n",
    "\tcopyfile(src, dst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create data generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "target_size = (150, 150)\n",
    "# prepare iterators\n",
    "train_set = datagen.flow_from_directory('dataset/train/', class_mode='binary', batch_size=64, target_size=target_size)\n",
    "test_set = datagen.flow_from_directory('dataset/test/', class_mode='binary', batch_size=64, target_size=target_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 1 block\n",
    "def VGG1():\n",
    "\tmodel = Sequential(name='VGG1')\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(target_size[0], target_size[1], 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 3 blocks\n",
    "def VGG3():\n",
    "\tmodel = Sequential(name='VGG3')\n",
    "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(target_size[0], target_size[1], 3)))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "\tmodel.add(MaxPooling2D((2, 2)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 16 Model\n",
    "def VGG_16():\n",
    "   # load model\n",
    "   model = VGG16(include_top=False, input_shape=(target_size[0], target_size[1], 3))\n",
    "   # mark loaded layers as not trainable\n",
    "   for layer in model.layers:\n",
    "      layer.trainable = False\n",
    "   # add new classifier layers\n",
    "   flat1 = Flatten()(model.layers[-1].output)\n",
    "   class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "   output = Dense(1, activation='sigmoid')(class1)\n",
    "   # define new model\n",
    "   model = Model(inputs=model.inputs, outputs=output, name='VGG16')\n",
    "   # compile model\n",
    "   opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "   model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "   return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history, name):\n",
    "\tfig, ax = plt.subplots(2, 1, figsize=(10, 10))\t\n",
    "\n",
    "\tax[0].plot(history.history['loss'], color='blue', label='train')\n",
    "\tax[0].plot(history.history['val_loss'], color='orange', label='test')\n",
    "\tax[0].set_title('Cross Entropy Loss')\n",
    "\tax[0].set_xlabel('Epochs')\n",
    "\tax[0].set_ylabel('Loss')\n",
    "\tax[0].legend()\n",
    "\n",
    "\tax[1].plot(history.history['accuracy'], color='blue', label='train')\n",
    "\tax[1].plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "\tax[1].set_title('Classification Accuracy')\n",
    "\tax[1].set_xlabel('Epochs')\n",
    "\tax[1].set_ylabel('Accuracy')\n",
    "\tax[1].legend()\n",
    "\t\n",
    "\t# save plot to file\n",
    "\tplt.savefig('plots/' + name + '_plot.png')\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def image_grid(imgs, preds):\n",
    "  \"\"\"Return a 5x5 grid of the MNIST images as a matplotlib figure.\"\"\"\n",
    "  figure = plt.figure(figsize=(10,10))\n",
    "  for i in range(40):\n",
    "    # Start next subplot.\n",
    "    plt.subplot(8, 5, i + 1, title=preds[i])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(imgs[i])\n",
    "\n",
    "  return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makedirs('plots', exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(columns=['Training time', 'Training loss', 'Training accuracy', 'Testing accuracy', 'Number of model parameters'], index=[\"VGG1\", \"VGG3\", \"VGG3_augmented\", \"VGG16\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree('logs', ignore_errors=True)\n",
    "shutil.rmtree('logs/fit/VGG3_augmented/', ignore_errors=True)\n",
    "shutil.rmtree('logs/predictions/VGG3_augmented/', ignore_errors=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Model is trained one by one and not with a for loop due Resource exhausting error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [VGG1, VGG3, VGG_16]\n",
    "# for model in models:\n",
    "with tf.device('/device:CPU:0'):\n",
    "\tmodel = VGG_16()\n",
    "\n",
    "\ttensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/fit/\" + model.name, update_freq='batch')\n",
    "\n",
    "\tstart = timeit.default_timer()\n",
    "\t# fit model\n",
    "\thistory = model.fit(train_set, steps_per_epoch=len(train_set), validation_data=test_set, validation_steps=len(test_set), epochs=20, verbose=0, callbacks=[tensorboard_callback])\n",
    "\texec_time = timeit.default_timer() - start\n",
    "\n",
    "\tpredictions = np.where((model.predict(test_set[0][0]) > 0.5).astype(\"int32\").reshape(-1) == 1, 'lion', 'kangaroo')\n",
    "\n",
    "\tfile_writer = tf.summary.create_file_writer(\"logs/predictions/\" + model.name)\n",
    "\n",
    "\tfigure = image_grid(test_set[0][0], predictions)\n",
    "\twith file_writer.as_default():\n",
    "\t\ttf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
    "\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(test_set, steps=len(test_set), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\tdf.loc[model.name, 'Training time'] = exec_time\n",
    "\tdf.loc[model.name, 'Testing accuracy'] = acc * 100.0\n",
    "\tdf.loc[model.name, 'Training accuracy'] = history.history['accuracy'][-1] * 100.0\n",
    "\tdf.loc[model.name, 'Training loss'] = history.history['loss'][-1]\n",
    "\tdf.loc[model.name, 'Number of model parameters'] = model.count_params()\n",
    "\t\t\n",
    "\t\t# learning curves\n",
    "\t\t# summarize_diagnostics(history, model.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.where((model.predict(test_set[0][0]) > 0.5).astype(\"int32\").reshape(-1) == 1, 'lion', 'kangaroo')\n",
    "predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 3 with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create data generators\n",
    "aug_train_datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "aug_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "aug_train_set = aug_train_datagen.flow_from_directory('dataset/train/',class_mode='binary', batch_size=64, target_size=target_size)\n",
    "aug_test_set = aug_test_datagen.flow_from_directory('dataset/test/',class_mode='binary', batch_size=64, target_size=target_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 77.500\n",
      "2/2 [==============================] - 0s 37ms/step\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:CPU:0'):\n",
    "\tmodel = VGG3()\n",
    "\n",
    "\ttensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/fit/VGG3_augmented\", update_freq=\"batch\")\n",
    "\n",
    "\tstart = timeit.default_timer()\n",
    "\thistory = model.fit(aug_train_set, steps_per_epoch=len(aug_train_set), validation_data=aug_test_set, validation_steps=len(aug_test_set), epochs=20, verbose=0, callbacks=[tensorboard_callback])\n",
    "\texec_time = timeit.default_timer() - start\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(aug_test_set, steps=len(aug_test_set), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\tpredictions = np.where((model.predict(aug_test_set[0][0]) > 0.5).astype(\"int32\").reshape(-1) == 1, 'lion', 'kangaroo')\n",
    "\n",
    "\tfile_writer = tf.summary.create_file_writer(\"logs/predictions/\" + model.name + \"_augmented\")\n",
    "\n",
    "\tfigure = image_grid(aug_test_set[0][0], predictions)\n",
    "\n",
    "\twith file_writer.as_default():\n",
    "\t\ttf.summary.image(\"Training data\", plot_to_image(figure), step=0)\n",
    "\n",
    "\tdf.loc[model.name + \"_augmented\", 'Training time'] = exec_time\n",
    "\tdf.loc[model.name + \"_augmented\", 'Testing accuracy'] = acc * 100.0\n",
    "\tdf.loc[model.name + \"_augmented\", 'Training accuracy'] = history.history['accuracy'][-1] * 100.0\n",
    "\tdf.loc[model.name + \"_augmented\", 'Training loss'] = history.history['loss'][-1]\n",
    "\tdf.loc[model.name + \"_augmented\", 'Number of model parameters'] = model.count_params()\n",
    "\n",
    "# # learning curves\n",
    "# summarize_diagnostics(history, model.name + \"_augmented\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_MLP():\n",
    "    model = Sequential(name='our_MLP')\n",
    "    model.add(Flatten(input_shape=(target_size[0], target_size[1], 3)))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 52.500\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "\tmodel = our_MLP()\n",
    "\n",
    "\tstart = timeit.default_timer()\n",
    "\thistory = model.fit(train_set, steps_per_epoch=len(train_set), validation_data=test_set, validation_steps=len(test_set), epochs=10, verbose=0)\n",
    "\texec_time = timeit.default_timer() - start\n",
    "\t# evaluate model\n",
    "\t_, acc = model.evaluate(test_set, steps=len(test_set), verbose=0)\n",
    "\tprint('> %.3f' % (acc * 100.0))\n",
    "\n",
    "\tdf.loc[model.name, 'Training time'] = exec_time\n",
    "\tdf.loc[model.name, 'Testing accuracy'] = acc * 100.0\n",
    "\tdf.loc[model.name, 'Training accuracy'] = history.history['accuracy'][-1] * 100.0\n",
    "\tdf.loc[model.name, 'Training loss'] = history.history['loss'][-1]\n",
    "\tdf.loc[model.name, 'Number of model parameters'] = model.count_params()\n",
    "\n",
    "\t# learning curves\n",
    "\t# summarize_diagnostics(history, model.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>Training loss</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Testing accuracy</th>\n",
       "      <th>Number of model parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGG1</th>\n",
       "      <td>10.173842</td>\n",
       "      <td>0.431681</td>\n",
       "      <td>83.749998</td>\n",
       "      <td>60.000002</td>\n",
       "      <td>23041153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG3</th>\n",
       "      <td>68.59395</td>\n",
       "      <td>0.464399</td>\n",
       "      <td>74.374998</td>\n",
       "      <td>69.999999</td>\n",
       "      <td>5401921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG3_augmented</th>\n",
       "      <td>65.54307</td>\n",
       "      <td>0.550922</td>\n",
       "      <td>75.625002</td>\n",
       "      <td>77.499998</td>\n",
       "      <td>5401921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG16</th>\n",
       "      <td>325.50215</td>\n",
       "      <td>0.148732</td>\n",
       "      <td>96.875</td>\n",
       "      <td>94.999999</td>\n",
       "      <td>15763521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our_MLP</th>\n",
       "      <td>4.862237</td>\n",
       "      <td>0.737315</td>\n",
       "      <td>50.625002</td>\n",
       "      <td>52.499998</td>\n",
       "      <td>73974785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Training time Training loss Training accuracy Testing accuracy  \\\n",
       "VGG1               10.173842      0.431681         83.749998        60.000002   \n",
       "VGG3                68.59395      0.464399         74.374998        69.999999   \n",
       "VGG3_augmented      65.54307      0.550922         75.625002        77.499998   \n",
       "VGG16              325.50215      0.148732            96.875        94.999999   \n",
       "our_MLP             4.862237      0.737315         50.625002        52.499998   \n",
       "\n",
       "               Number of model parameters  \n",
       "VGG1                             23041153  \n",
       "VGG3                              5401921  \n",
       "VGG3_augmented                    5401921  \n",
       "VGG16                            15763521  \n",
       "our_MLP                          73974785  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pandas dataframe to csv\n",
    "df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training time</th>\n",
       "      <th>Training loss</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Testing accuracy</th>\n",
       "      <th>Number of model parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGG1</th>\n",
       "      <td>10.173842</td>\n",
       "      <td>0.431681</td>\n",
       "      <td>83.749998</td>\n",
       "      <td>60.000002</td>\n",
       "      <td>23041153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG3</th>\n",
       "      <td>68.593950</td>\n",
       "      <td>0.464399</td>\n",
       "      <td>74.374998</td>\n",
       "      <td>69.999999</td>\n",
       "      <td>5401921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG3_augmented</th>\n",
       "      <td>65.543070</td>\n",
       "      <td>0.550922</td>\n",
       "      <td>75.625002</td>\n",
       "      <td>77.499998</td>\n",
       "      <td>5401921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGG16</th>\n",
       "      <td>325.502150</td>\n",
       "      <td>0.148732</td>\n",
       "      <td>96.875000</td>\n",
       "      <td>94.999999</td>\n",
       "      <td>15763521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>our_MLP</th>\n",
       "      <td>4.862237</td>\n",
       "      <td>0.737315</td>\n",
       "      <td>50.625002</td>\n",
       "      <td>52.499998</td>\n",
       "      <td>73974785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Training time  Training loss  Training accuracy  \\\n",
       "VGG1                10.173842       0.431681          83.749998   \n",
       "VGG3                68.593950       0.464399          74.374998   \n",
       "VGG3_augmented      65.543070       0.550922          75.625002   \n",
       "VGG16              325.502150       0.148732          96.875000   \n",
       "our_MLP              4.862237       0.737315          50.625002   \n",
       "\n",
       "                Testing accuracy  Number of model parameters  \n",
       "VGG1                   60.000002                    23041153  \n",
       "VGG3                   69.999999                     5401921  \n",
       "VGG3_augmented         77.499998                     5401921  \n",
       "VGG16                  94.999999                    15763521  \n",
       "our_MLP                52.499998                    73974785  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pandas dataframe from csv\n",
    "ldf = pd.read_csv('results.csv', index_col=0)\n",
    "ldf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
